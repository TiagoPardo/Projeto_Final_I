---
title: "Projeto Integrador - Modelagem"
author: "Andre Giusti Dambry, Flavio Barbosa Shirahige, Michel Maurice Conjaud Neto e Tiago Evangelista Pardo"
date: "2023-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(rpart)
library(rpart.plot)
library(partykit)
library(skimr)
library(glmnet)
library(plotmo)
library(naniar)
library(rsample)
library(tidyverse)
library(yardstick)
library(modeldata)
library(ranger)
library(MASS)
library(patchwork)
library(vip)
library(gbm)
library(xgboost)
library(ranger)
library(pROC)
```

## Objetivo

O objetivo desse trabalho é qual é o modelo que melhor prevê se uma empresa irá falir em até dois anos. A variável resposta desse processo de modelagem é will_close: 1 significa que a empresa fechará em até 2 anos e ZERO (0) implica em não fechamento nesse mesmo período.

Para tal, serão utilizados os modelos de regressão logística, RIDGE/LASSO, floresta aleatória e Boosting.

O primeiro passo é importar os dados. Serão removidos os ID das empresas (comp_id), pois esses dados não serão utilizados na modelagem:

```{r}
dados <- read_csv("C:/Users/Flavio/Dropbox/My PC (LAPTOP-FVTATBSD)/Documents/Pós Insper Data Science/Projeto Integrador AEM I e CCD/dados_bisnode.csv", show_col_types = FALSE) %>% 
  dplyr::select(-comp_id)
```


# ATENÇÃO: usei o código abaixo para excluir os missing values, pois na base que usei havia alguns. Assim, essa linha deve ser deconsiderada no trabalho final.
```{r}
dados <- na.omit(dados)
```


O próximo passo é verificar se os dados foram migrados corretamente. 
```{r}
skim(dados)
```


Como há variáveis categóricas, vamos transformá-las em fator para a modelagem: 
```{r}
dados <- dados %>% 
  mutate_if(is.character, ~as.factor(.x))
```


## Análise dos Modelos

Nesse item serão construídos e analisados os modelos para prever os preços dos alugueis. São eles:

- Regressão Logísitica
- Rigde
- LASSO
- Floresta Aleatória
- Boosting

A etapa seguinte é criar os datasets de treinamento e teste, onde 80% do dataset será de treinamento:

```{r}
set.seed(123)

idx <- sample(nrow(dados), size = .80 * nrow(dados), replace = FALSE)

treino <- dados[idx,]
teste  <- dados[-idx,]
```


### Regressão Logística

Agora será estimado o modelo de regressão logística:
```{r}
log <- glm(will_close ~ ., data = treino, family = "binomial")
summary(log)
```

Aplicando o modelo de previsão nos dados de teste para estimar as probabilidades:

```{r}
prob_log <- predict(log, newdata = teste, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log, 
                   classes = teste$will_close, 
                   metodo = "logística")
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística")
```

### Modelo Ridge

O próximo modelo a ser estimado é o Ridge. Antes, deverão ser preparadados os datasets de treinamento e teste para aplicação da função do pacote glmnet.

```{r}
X_treino <- model.matrix(will_close ~ ., dados)[idx,-1]
y_treino <- dados$will_close[idx]

X_teste <- model.matrix(will_close ~ ., dados)[-idx,-1]
y_teste <- dados$will_close[-idx]
```

Criando o modelo Ridge e plotando o gráfico com os lambdas variando até 500:

```{r}
ridge <- glmnet(X_treino, y_treino,  alpha = 0, nlambda = 500, family = "binomial")
plot_glmnet(ridge, lwd = 2, cex.lab = 1.3)
```

Fazendo a validação cruzadas do modelo:

```{r}
cv_ridge <- cv.glmnet(X_treino, y_treino, alpha = 0, family = "binomial")
plot(cv_ridge, cex.lab = 1.3)
```
Aplicando o modelo de previsão com base no melhor lambda (menor erro) e estimando as probabilidades a partir da base de teste:

```{r}
prob_ridge <- predict(ridge, newx = X_teste, s = cv_ridge$lambda.min, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = as.numeric(prob_ridge), 
                   classes = y_teste, 
                   metodo = "ridge"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(ridge, mapping = aes(fill = Sign)) + labs(title = "Rigde")
```

### Regressão LASSO

O modelo seguinte a ser criado é o LASSO. Abaixo, foi criado o modelo LASSO e plotado o gráfico com os lambdas variando até 500:

```{r}
lasso <- glmnet(X_treino, y_treino,  alpha = 1, nlambda = 500, family = "binomial")
plot_glmnet(lasso, lwd = 2, cex.lab = 1.3)
```

Fazendo a validação cruzadas do modelo:

```{r}
cv_lasso <- cv.glmnet(X_treino, y_treino, alpha = 1, family = "binomial")
plot(cv_lasso, cex.lab = 1.3)
```

Aplicando o modelo de previsão com base no melhor lambda (menor erro) e estimando as probabilidades a partir da base de teste:

```{r}
prob_lasso <- predict(lasso, newx = X_teste, s = cv_lasso$lambda.min, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Lasso e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = as.numeric(prob_lasso), 
                   classes = y_teste, 
                   metodo = "lasso"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(lasso, mapping = aes(fill = Sign)) + labs(title = "LASSO")
```


### Floresta Aleatória

Agora, será criado e testado o modelo de floresta aleatória com 500 árvores e com todas as variáveis:

```{r}
rf <- ranger(will_close ~ ., probability = TRUE, data = dados)
```

Para essa floresta aleatória com 500 árvores e com todas as variáveis, vamos fazer a previsão a partir dos dados de teste:

```{r}
prob_rf <- predict(rf, teste)$predictions[,1]
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_rf, 
                   classes = teste$will_close, 
                   metodo = "floresta aleatória"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo de floresta aleatória:

```{r}
vip(ranger(will_close ~ ., probability = TRUE, importance = "permutation", data = dados), aesthetics = list(fill = "lightblue")) + labs(title = "Floresta Aleatoria")
```

Testando de 1 a 500 de árvores e o numero de variaveis por split:

```{r}
result_arvores <- crossing(mtry = c(2, 4, 6, 8, 10),
                       n_arvores = c(1:10, seq(10, 500, 10)))
itera <- function(mtry, n_arvores) {
  rf_itera <- ranger(will_close ~ ., probability = TRUE, num.trees = n_arvores, mtry = mtry, data = dados)
  return(rf_itera$prediction.error)
}
result_arvores <- result_arvores %>%
  mutate(erro = map2_dbl(mtry, n_arvores, itera))
head(result_arvores)

result_arvores %>% ggplot(aes(n_arvores, erro)) + 
 geom_line(color = "#5B5FFF", size = 1.2) + 
 labs(x = "Número de Árvores", y = "Erro de Classificação (OOB)") + 
 theme_bw()

```

Encontrando a floresta ótima (número de árvores e número de variáveis por split) com o menor erro:

```{r}
floresta_otima <- result_arvores %>% as_tibble() %>% filter(erro== min(erro))#Obtendo dados da floresta ótima
mtry_otimo <- floresta_otima$mtry #numero de arvores para floresta otima
n_arvores_otimo <- floresta_otima$n_arvores # variaveis por split

```
Criando e modelo de floresta aleatória ótima:

```{r}
rf_otima <- ranger(will_close ~ ., probability = TRUE, num.trees = n_arvores_otimo, mtry = mtry_otimo, data = dados)
```

Para essa floresta aleatória com 500 árvores e com todas as variáveis, vamos fazer a previsão a partir dos dados de teste:

```{r}
prob_rf_otima <- predict(rf_otima, teste)$predictions[,1]
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_rf_otima, 
                   classes = teste$will_close, 
                   metodo = "floresta aleatória ótima"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo de floresta aleatória otimizada:

```{r}
vip(ranger(will_close ~ ., probability = TRUE, importance = "permutation", num.trees = n_arvores_otimo, mtry = mtry_otimo, data = dados), 
    aesthetics = list(fill = "lightblue")) + labs(title = "Floresta Aleatoria Ótima")
```


### Boosting

Agora, será criado e testado o modelo de Boosting com 500 árvores e taxa de aprendizagem 0,05:

```{r}
(fit_bst <- gbm(will_close ~ ., distribution = "bernoulli", n.trees = 500, 
                interaction.depth = 4, shrinkage = 0.05, data = treino))
summary(fit_bst)
```

Fazendo a validação cruzadas do modelo paa obter o número de árvores ótimo:

```{r}
fit_cv <- gbm(will_close ~ ., data = treino, cv.folds = 5, n.trees = 500, 
              interaction.depth = 4, distribution = "bernoulli", shrinkage = 0.05)

num_arv_boost <- gbm.perf(fit_cv, method = "cv") #obtendo a árvore ótima

```

Aplicando o modelo de previsão com base na melhor quantidade de árvores (menor erro) e estimando as probabilidades a partir da base de teste:

```{r}
prob_gbm <- predict(fit_cv, teste, n.trees = num_arv_boost, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_gbm, 
                   classes = teste$will_close, 
                   metodo = "boosting"))
```


Agora vamos otimizar o número de variaveis para verificar se o erro da regressão logística é reduzido. Para tal, será utilizado o método stepwise.

### Regressão logística com stepwise

```{r}
modelo_stepAIC <- stepAIC(log, direction = "both")
lista_var <- append(attr(terms(modelo_stepAIC ), "term.labels"), "will_close")
dados_stepwise <- subset(dados, select = lista_var)

```

Criando os datasets de treino e teste do modelo com stepwise:

```{r}
treino_stepwise <- subset(treino, select = lista_var)
teste_stepwise  <- subset(teste, select = lista_var)
```


Agora será estimado o modelo de regressão logística com stepwise:
```{r}
log_stepwise <- glm(will_close ~ ., data = treino_stepwise, family = "binomial")
summary(log_stepwise)
```

Aplicando o modelo de previsão com stepwise nos dados de teste para estimar as probabilidades:

```{r}
prob_log_stepwise <- predict(log_stepwise, newdata = teste_stepwise, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística com stepwise e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log_stepwise, 
                   classes = teste_stepwise$will_close, 
                   metodo = "logística stepwise")
```

### Regressão Logística com Número de Variáveis Reduzido

Conforme já descrito por meio da matriz de correlação na etapa de análise exploratória dos dados, há algumas variáveis que são correlacionadas. Assim, vamos excluir as variáveis que tem alta correlação com outras e estimar o modelo de regressão logística. O primeiro passo é criar um dataset sem essas variáveis:

```{r}
treino_reduz <- subset(treino, select = -c()) #inserir as variáveis a serem excluídas
teste_reduz <- subset(teste, select = -c()) #inserir as variáveis a serem excluídas
```

Vamos estimar o modelo de regressão logística com variáveis reduzidas:

```{r}
log_reduz <- glm(will_close ~ ., data = treino_reduz, family = "binomial")
summary(log_reduz)
```

Aplicando o modelo de previsão nos dados de teste para estimar as probabilidades:

```{r}
prob_log_reduz <- predict(log_reduz, newdata = teste_reduz, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística reduzida e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log_reduz, 
                   classes = teste_reduz$will_close, 
                   metodo = "logística reduzida")
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log_reduz, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística")
```


### Regressão Logística por Porte

Durante o processo para estimar o modelo de regressão logística, o R fez um alerta que pode ser resultado no número elevado de outliers do dataset. Assim, para tentar minimizar, vamos estimar o modelo de regressão logítica por porte, dividindo em 3 datasets de pequenas, médias e grandes empresas, conforme já definido na análise explotarória. Isso pode melhorar a performance do modelo, mas pode trazer algum prejuízo em virtude da redução do número de observações por modelo. 
Assim, vamos criar dividir o dataset em 3 subgrupos (equenas, médias e grandes empresas):

```{r}
dados_pequena <- dados %>%
  filter(XXX == 'Pequena') #incluir o nome da coluna que possui os dados de porte e colocar o nome do porte como pequena
dados_pequena <- subset(dados_pequena, select = -c()) #incluir o nome da coluna que possui os dados de porte para excluí-la

dados_media <- dados %>%
  filter(XXX == 'Media') #incluir o nome da coluna que possui os dados de porte e colocar o nome do porte como media
dados_media<- subset(dados_media, select = -c()) #incluir o nome da coluna que possui os dados de porte para excluí-la

dados_grande <- dados %>%
  filter(XXX == 'Grande') #incluir o nome da coluna que possui os dados de porte e colocar o nome do porte como grande
dados_grande <- subset(dados_grande, select = -c()) #incluir o nome da coluna que possui os dados de porte para excluí-la
```


Criando os datasets de treino e teste para cada um dos portes:
```{r}
idx_pequena <- sample(nrow(dados_pequena), size = .80 * nrow(dados), replace = FALSE)
idx_media <- sample(nrow(dados_media), size = .80 * nrow(dados), replace = FALSE)
idx_grande <- sample(nrow(dados_grande), size = .80 * nrow(dados), replace = FALSE)

treino_pequena <- dados[idx_pequena,]
teste_pequena <- dados[-idx_pequena,]

treino_media <- dados[idx_media,]
teste_media  <- dados[-idx_media,]

treino_grande <- dados[idx_grande,]
teste_grande  <- dados[-idx_grande,]

```

#### Regressão Logística das Empresas de Pequeno Porte

Vamos estimar o modelo de regressão logística para as empresas de pequeno porte:

```{r}
log_pequena <- glm(will_close ~ ., data = treino_pequena, family = "binomial")
summary(log_pequena)
```

Aplicando o modelo de previsão para as empresas de pequeno porte nos dados de teste para estimar as probabilidades:

```{r}
prob_log_pequena <- predict(log_pequena, newdata = teste_pequena, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística para as empresas de pequeno porte e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log_pequena, 
                   classes = teste_pequena$will_close, 
                   metodo = "logística pequeno porte")
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log_pequena, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística para Pequeno Porte")
```


#### Regressão Logística das Empresas de Médio Porte

Vamos estimar o modelo de regressão logística para as empresas de pequeno porte:

```{r}
log_media <- glm(will_close ~ ., data = treino_media, family = "binomial")
summary(log_media)
```

Aplicando o modelo de previsão para as empresas de pequeno porte nos dados de teste para estimar as probabilidades:

```{r}
prob_log_media <- predict(log_media, newdata = teste_pequena, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística para as empresas de pequeno porte e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log_media, 
                   classes = teste_media$will_close, 
                   metodo = "logística pequeno porte")
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log_media, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística para Médio Porte")
```

#### Regressão Logística das Empresas de Grande Porte

Vamos estimar o modelo de regressão logística para as empresas de pequeno porte:

```{r}
log_grande <- glm(will_close ~ ., data = treino_grande, family = "binomial")
summary(log_grande)
```

Aplicando o modelo de previsão para as empresas de pequeno porte nos dados de teste para estimar as probabilidades:

```{r}
prob_log_grande <- predict(log_grande, newdata = teste_grande, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pela regressão logística para as empresas de pequeno porte e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log_grande, 
                   classes = teste_grande$will_close, 
                   metodo = "logística pequeno porte")
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log_grande, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística para Grande Porte")
```


### Análise dos Modelos Estimados

Vamos plotar a curva ROC:

```{r}
desempenho %>% 
  mutate(classes = factor(classes)) %>% 
  group_by(metodo) %>% 
  roc_curve(classes, prob, event_level = "second") %>% 
  autoplot()
```

Vamos analisar AUC para cada modelo estimado:

```{r}
desempenho %>% 
  mutate(classes = factor(classes)) %>% 
  group_by(metodo) %>% 
  roc_auc(classes, prob, event_level = "second") %>% 
  arrange(desc(.estimate))
```
