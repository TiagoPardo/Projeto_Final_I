---
title: "Projeto Integrador - Modelagem"
author: "Andre Giusti Dambry, Flavio Barbosa Shirahige, Michel Maurice Conjaud Neto e Tiago Evangelista Pardo"
date: "2023-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(rpart)
library(rpart.plot)
library(partykit)
library(skimr)
library(glmnet)
library(plotmo)
library(naniar)
library(rsample)
library(tidyverse)
library(yardstick)
library(modeldata)
library(ranger)
library(MASS)
library(patchwork)
library(vip)
library(gbm)
library(xgboost)
library(ranger)
library(pROC)
```

## Etapa de Modelagem - Introdução

O objetivo dessa parte do Projeto Integrador é desenvolver um modelo previtivo para indicar se uma empresa irá falir em até dois anos a partir da avaliação de cinco classes de modelos: regressão logística, RIDGE, LASSO, floresta aleatória e Boosting. O pipeline de pré-processamento dos dados foi feito em Python. Nessa etapa de pré-processamento, foi criada a variável chamada will_close, que é a variável resposta desse processo de modelagem. Nela, o valor "1" significa que a empresa fechará em até 2 anos e ZERO (0) que a empresa não fechou nesse mesmo período de dois anos após 2012 (ano de referência para a modelagem).

Além dos 5 modelos listados acima, serão utilizadas outras abordagens, como implementar o método de seleção de subconjuntos para as variáveis preditoras (stepwise) e testar o desempenho para modelagem por porte da empresa (pequena, média e grande), a ser feito de forma separada.

Para avaliar o desempenho de cada um dos modelos de classificação estimados, será utilizado a área sob a curva ROC (AUC), que mede a probabilidade de uma observação de evento ocorrer (no caso, se a empresa irá fechar) ter uma probabilidade maior do que uma observação do grupo de referência. Isto é, qual é o percentual de classificação correta do modelo em questão. Logo, um valor de AUC de um dado modelo igual 1 indica um desempenho de 100% na classificação e um valor de 0,5 significa que o modelo não é capaz de classificar de forma melhor do que uma escolha num processo aleatório.

O primeiro passo é importar os dados. Serão removidos os ID das empresas (comp_id), pois essas informações não serão utilizados na modelagem:

```{r}
dados <- read_csv("C:/Users/Flavio/Dropbox/My PC (LAPTOP-FVTATBSD)/Documents/Pós Insper Data Science/Projeto Integrador AEM I e CCD/df.csv", show_col_types = FALSE) %>% 
  dplyr::select(-comp_id, -revenue, -log_sales, -curr_idx_liq)
```


A próxima etapa é verificar se os dados foram migrados corretamente. 
```{r}
skim(dados)
```


Como há variáveis categóricas, vamos transformá-las em fator para a modelagem: 
```{r}
dados <- dados %>% 
  mutate_if(is.character, ~as.factor(.x))
```


## Análise dos Modelos

Nesse passo, vamos construir os modelos para predizer a variável resposta will_close (se a empresa irá falir em até dois anos), a saber:

- Regressão Logísitica
- Rigde
- LASSO
- Floresta Aleatória
- Boosting

A etapa seguinte é criar os datasets de treinamento e teste, onde 80% do dataset será de treinamento:

```{r}
set.seed(123)

idx <- sample(nrow(dados), size = .80 * nrow(dados), replace = FALSE)

treino <- dados[idx,]
teste  <- dados[-idx,]
```


### Regressão Logística

O primeiro modelo a ser estimado é o de regressão logística:
```{r}
log <- glm(will_close ~ ., data = treino, family = 'binomial')
summary(log)
```
A aplicação da função glm do R gerou o alerta ("warning") a seguir: "Warning: glm.fit: probabilidades ajustadas numericamente 0 ou 1 ocorreu". Esse alerta pode ser causado por outliers. Para tentar  mitigar esse problema, vamos posteriormente dividir o dataset de acordo com o porte da empresa e estimar o modelo de regressão logística para cada um dos porte. Por ora, vamos continuar na estimativa e avaliação dos 5 modelos descritos acima.

Agora, vamos aplicar o modelo de previsão nos dados de teste para estimar as probabilidades:

```{r}
prob_log <- predict(log, newdata = teste, type = "response")
```

E armazenar em um tibble os resultados das probabilidades obtidas pela regressão logística e a respectiva classe observada:

```{r}
desempenho <- tibble(prob = prob_log, 
                   classes = teste$will_close, 
                   metodo = "logística")
```

Abaixo, foi plotado o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística")
```

### Modelo Ridge

O próximo modelo a ser estimado é o Ridge. Primeiro, deverão ser preparadados os datasets de treinamento e teste para aplicação da função do pacote glmnet.

```{r}
X_treino <- model.matrix(will_close ~ ., dados)[idx,-1]
y_treino <- dados$will_close[idx]

X_teste <- model.matrix(will_close ~ ., dados)[-idx,-1]
y_teste <- dados$will_close[-idx]
```

Abaixo, foi criado o modelo Ridge e plotando o gráfico com os lambdas variando até 500:

```{r}
ridge <- glmnet(X_treino, y_treino,  alpha = 0, nlambda = 500, family = "binomial")
plot_glmnet(ridge, lwd = 2, cex.lab = 1.3)
```

A seguir, vamos fazer a validação cruzada do modelo:

```{r}
cv_ridge <- cv.glmnet(X_treino, y_treino, alpha = 0, family = "binomial")
plot(cv_ridge, cex.lab = 1.3)
```
Vamos aplicar o modelo de previsão com base no melhor lambda (menor erro), estimando as probabilidades a partir da base de teste:

```{r}
prob_ridge <- predict(ridge, newx = X_teste, s = cv_ridge$lambda.min, type = "response")
```

E armazenar em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = as.numeric(prob_ridge), 
                   classes = y_teste, 
                   metodo = "ridge"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo Rigde:

```{r}
vip(ridge, mapping = aes(fill = Sign)) + labs(title = "Rigde")
```

### Regressão LASSO

O modelo seguinte a ser criado é o LASSO. Assim como no modelo Ridge, foi criado o modelo LASSO e plotado o gráfico com os lambdas variando até 500:

```{r}
lasso <- glmnet(X_treino, y_treino,  alpha = 1, nlambda = 500, family = "binomial")
plot_glmnet(lasso, lwd = 2, cex.lab = 1.3)
```

O próximo passo é fazer a validação cruzada do modelo:

```{r}
cv_lasso <- cv.glmnet(X_treino, y_treino, alpha = 1, family = "binomial")
plot(cv_lasso, cex.lab = 1.3)
```

Agora, será aplicado o modelo de previsão com base no melhor lambda (menor erro), estimando as probabilidades a partir da base de teste:

```{r}
prob_lasso <- predict(lasso, newx = X_teste, s = cv_lasso$lambda.min, type = "response")
```

E armazenado em um tibble os resultados das probabilidades obtidas pelo modelo Lasso e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = as.numeric(prob_lasso), 
                   classes = y_teste, 
                   metodo = "lasso"))
```

Abaixo, foi plotado o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(lasso, mapping = aes(fill = Sign)) + labs(title = "LASSO")
```


### Floresta Aleatória

O próximo modelo que será criado e testado é o de floresta aleatória com 500 árvores e com todas as variáveis:

```{r}
rf <- ranger(will_close ~ ., probability = TRUE, data = treino)
```

Para essa floresta aleatória com 500 árvores e com todas as variáveis, vamos fazer a previsão a partir dos dados de teste:

```{r}
prob_rf <- predict(rf, teste)$predictions[,2]
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo de floresta aleatória e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_rf, 
                   classes = teste$will_close, 
                   metodo = "floresta aleatória"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo de floresta aleatória:

```{r}
vip(ranger(will_close ~ ., probability = TRUE, importance = "permutation", data = dados), aesthetics = list(fill = "lightblue")) + labs(title = "Floresta Aleatoria")
```

Agora, vamos iterar para testar o número de árvores de 1 a 500, bem como o número de variáveis por split, plotar o resultado dessa iteração:

```{r}
result_arvores <- crossing(mtry = c(2, 4, 8, 12, 16, 20, 23), #número de variáveis por split a ser testados
                       n_arvores = c(1:10, seq(10, 500, 10)))
itera <- function(mtry, n_arvores) {
  rf_itera <- ranger(will_close ~ ., probability = TRUE, num.trees = n_arvores, mtry = mtry, data = treino)
  return(rf_itera$prediction.error)
}
result_arvores <- result_arvores %>%
  mutate(erro = map2_dbl(mtry, n_arvores, itera))
head(result_arvores)

result_arvores %>% ggplot(aes(n_arvores, erro)) + 
 geom_line(color = "#5B5FFF", size = 1.2) + 
 labs(x = "Número de Árvores", y = "Erro de Classificação (OOB)") + 
 theme_bw()

```

A partir da iteração acima, vamos obter os dados da floresta ótima (número de árvores e número de variáveis por split) com o menor erro:

```{r}
floresta_otima <- result_arvores %>% as_tibble() %>% filter(erro== min(erro))#Obtendo dados da floresta ótima
mtry_otimo <- floresta_otima$mtry #numero de arvores para floresta otima
n_arvores_otimo <- floresta_otima$n_arvores # variaveis por split

```
E criar o modelo de floresta aleatória ótima:

```{r}
rf_otima <- ranger(will_close ~ ., probability = TRUE, num.trees = n_arvores_otimo,
                   mtry = mtry_otimo, data = treino)
```

Para essa floresta aleatória ótima, vamos fazer a previsão a partir dos dados de teste:

```{r}
prob_rf_otima <- predict(rf_otima, teste)$predictions[,2]
```

E armazenar em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_rf_otima, 
                   classes = teste$will_close, 
                   metodo = "floresta aleatória ótima"))
```

Abaixo, plotamos o gráfico com a importância de cada variável para esse modelo de floresta aleatória otimizada:

```{r}
vip(ranger(will_close ~ ., probability = TRUE, importance = "permutation", num.trees = n_arvores_otimo, mtry = mtry_otimo, data = treino), 
    aesthetics = list(fill = "lightblue")) + labs(title = "Floresta Aleatoria Ótima")
```


### Boosting

O último modelo que será criado e testado nesse ciclo de modelagem é o Boosting com 500 árvores e taxa de aprendizagem 0,05:

```{r}
(fit_bst <- gbm(will_close ~ ., distribution = "bernoulli", n.trees = 500, 
                interaction.depth = 4, shrinkage = 0.05, data = treino))
summary(fit_bst)
```

O passo seguinte é fazer a validação cruzadas do modelo para obter o número de árvores ótimo:

```{r}
fit_cv <- gbm(will_close ~ ., data = treino, cv.folds = 5, n.trees = 500, 
              interaction.depth = 4, distribution = "bernoulli", shrinkage = 0.05)

num_arv_boost <- gbm.perf(fit_cv, method = "cv") #obtendo a árvore ótima

```

Aplicando o modelo de previsão com base na melhor quantidade de árvores (menor erro) e estimando as probabilidades a partir da base de teste, temos:

```{r}
prob_gbm <- predict(fit_cv, teste, n.trees = num_arv_boost, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada, temos:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_gbm, 
                   classes = teste$will_close, 
                   metodo = "boosting"))
```

### Regressão logística com stepwise

Após estimar os cincos modelos acima, vamos verificar se a redução de variáveis para o modelo de regressão logística melhora o desempenho deste. Para tal, será utilizado o método stepwise.
Assim, vamos selecionar primeiro as variáveis a serem utilizadas por meio do método stepwise:

```{r}
modelo_stepAIC <- stepAIC(log, direction = "both")
lista_var <- append(attr(terms(modelo_stepAIC ), "term.labels"), "will_close")
dados_stepwise <- subset(dados, select = lista_var)

```

Após a seleção de variáveis, vamos criar os datasets de treino e teste:

```{r}
treino_stepwise <- subset(treino, select = lista_var)
teste_stepwise  <- subset(teste, select = lista_var)
```


Agora será estimado o modelo de regressão logística com stepwise:
```{r}
log_stepwise <- glm(will_close ~ ., data = treino_stepwise, family = "binomial")
summary(log_stepwise)
```

E aplicado o modelo de previsão com stepwise nos dados de teste para estimar as probabilidades:

```{r}
prob_log_stepwise <- predict(log_stepwise, newdata = teste_stepwise, type = "response")
```

Feito isso, vamos armazenar em um tibble os resultados das probabilidades obtidas pela regressão logística com stepwise e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_log_stepwise, 
                   classes = teste_stepwise$will_close, 
                   metodo = "logística stepwise"))
```


### Regressão Logística sem Outliers

Durante o processo para estimar o modelo de regressão logística, foi feito um alerta que pode ser resultado no número elevado de outliers do dataset, conforme já apontado acima. Assim, vamos estimar o modelo de regressão logítica sem os outliers, utilizando o método de critério IQR (Intervalo Interquartil) para ver se o desempenho dos modelos melhoram.

Nesse caso, o primeiro caso é eliminar os outliers. Como os outliers estão concentrados no limite superior da coluna 'sales', vamos excluir somente esses valores.

```{r}
Q1 <- quantile(dados$sales_x, 0.25)
Q3 <- quantile(dados$sales_x, 0.75)
IQR <- Q3 - Q1

ls <- Q3 + 1.5 * IQR

dados_sem_outliers <- subset(dados, sales_x <= ls)
```

A etapa seguinte é criar os datasets de treinamento e teste, onde 80% do dataset será de treinamento:

```{r}
idx_sem_outliers <- sample(nrow(dados_sem_outliers), size = .80 * nrow(dados_sem_outliers), replace = FALSE)

treino_sem_outliers <- dados_sem_outliers[idx_sem_outliers,]
teste_sem_outliers  <- dados_sem_outliers[-idx_sem_outliers,]
```


O primeiro modelo a ser estimado é o de regressão logística:
```{r}
log_sem_outliers <- glm(will_close ~ ., data = treino_sem_outliers, family = 'binomial')
summary(log_sem_outliers)
```
A aplicação da função glm do R gerou o alerta ("warning") a seguir: "Warning: glm.fit: probabilidades ajustadas numericamente 0 ou 1 ocorreu". Esse alerta pode ser causado por outliers. Para tentar  mitigar esse problema, vamos posteriormente dividir o dataset de acordo com o porte da empresa e estimar o modelo de regressão logística para cada um dos porte. Por ora, vamos continuar na estimativa e avaliação dos 5 modelos descritos acima.

Agora, vamos aplicar o modelo de previsão nos dados de teste para estimar as probabilidades:

```{r}
prob_log_sem_outliers <- predict(log_sem_outliers, newdata = teste_sem_outliers, type = "response")
```

E armazenar em um tibble os resultados das probabilidades obtidas pela regressão logística e a respectiva classe observada:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_log_sem_outliers, 
                   classes = teste_sem_outliers$will_close, 
                   metodo = "logística sem outliers"))
```

Abaixo, foi plotado o gráfico com a importância de cada variável para esse modelo:

```{r}
vip(log, mapping = aes(fill = Sign)) + labs(title = "Modelo de Regressão Logística")
```


### Boosting sem outliers

Agora, será criado e testado nesse ciclo de modelagem é o Boosting com 500 árvores e taxa de aprendizagem 0,05 sem os outliers:

```{r}
(fit_bst_sem_outliers <- gbm(will_close ~ ., distribution = "bernoulli", n.trees = 500, 
                interaction.depth = 4, shrinkage = 0.05, data = treino_sem_outliers))
summary(fit_bst_sem_outliers)
```

O passo seguinte é fazer a validação cruzadas do modelo para obter o número de árvores ótimo:

```{r}
fit_cv_sem_outliers <- gbm(will_close ~ ., data = treino_sem_outliers, cv.folds = 5, n.trees = 500, 
              interaction.depth = 4, distribution = "bernoulli", shrinkage = 0.05)

num_arv_boost_sem_outliers <- gbm.perf(fit_cv_sem_outliers, method = "cv") #obtendo a árvore ótima

```

Aplicando o modelo de previsão com base na melhor quantidade de árvores (menor erro) e estimando as probabilidades a partir da base de teste, temos:

```{r}
prob_gbm_sem_outliers <- predict(fit_cv_sem_outliers, teste_sem_outliers, n.trees = num_arv_boost_sem_outliers, type = "response")
```

E armazenando em um tibble os resultados das probabilidades obtidas pelo modelo Ridge e a respectiva classe observada, temos:

```{r}
desempenho <- desempenho %>% 
  bind_rows(tibble(prob = prob_gbm_sem_outliers, 
                   classes = teste_sem_outliers$will_close, 
                   metodo = "boosting sem outliers"))
```

### Análise dos Modelos Estimados

Vamos plotar a curva ROC:

```{r}
desempenho %>% 
  mutate(classes = factor(classes)) %>% 
  group_by(metodo) %>% 
  roc_curve(classes, prob, event_level = "second") %>% 
  autoplot()
```

Vamos analisar AUC para cada modelo estimado:

```{r}
desempenho %>% 
  mutate(classes = factor(classes)) %>% 
  group_by(metodo) %>% 
  roc_auc(classes, prob, event_level = "second") %>% 
  arrange(desc(.estimate))
```
